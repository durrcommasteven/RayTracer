{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Raytracing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt \n",
    "import einops\n",
    "import itertools\n",
    "import numpy as np \n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from icosphere import icosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Environment:\n",
    "    \"\"\" \n",
    "    An environment containing spheres and triangles \n",
    "    \"\"\"\n",
    "    sphere_positions: torch.Tensor\n",
    "    sphere_radii: torch.Tensor\n",
    "    triangles: torch.Tensor\n",
    "    object_idxs: torch.Tensor\n",
    "    device: str = 'cpu'\n",
    "    dtype: torch.dtype = torch.float64\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.sphere_positions.shape[0]==self.sphere_radii.shape[0]\n",
    "\n",
    "        self.to(device=self.device, dtype=self.dtype)\n",
    "    \n",
    "    def to(self, device, dtype):\n",
    "        self.sphere_positions = self.sphere_positions.to(dtype=dtype, device=device)\n",
    "        self.sphere_radii = self.sphere_radii.to(dtype=dtype, device=device)\n",
    "        self.triangles = self.triangles.to(dtype=dtype, device=device)\n",
    "        self.object_idxs = self.object_idxs.to(dtype=torch.int32, device=device)\n",
    "\n",
    "        self.device = device \n",
    "        self.type=dtype\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_wall_idx(vertices):\n",
    "    \"\"\"Which wall is this?\n",
    "    return the index of the wall\n",
    "\n",
    "    vertices is a tensor of shape (N, 3 vectors, 3 dims)\n",
    "    \"\"\"\n",
    "    N, _, _ = vertices.shape\n",
    "    # which axis all match\n",
    "    all_zeros = (vertices.sum(-2)==0)*1\n",
    "    all_ones = (vertices.sum(-2)==3)*1\n",
    "\n",
    "    output = all_ones.any(-1)*3 + all_zeros.argmax(-1) + all_ones.argmax(-1)\n",
    "\n",
    "    return output\n",
    "\n",
    "def make_room():\n",
    "    # now create the environment\n",
    "    central_vertices = [\n",
    "        [0,0,0], [1,0,1], [0,1,1], [1,1,0]\n",
    "    ]\n",
    "\n",
    "    all_vertices = []\n",
    "\n",
    "    for central_vertex in central_vertices:\n",
    "        other_verts = []\n",
    "        for i in range(3):\n",
    "            other_verts.append(\n",
    "                [x if j!=i else 1-x for j, x in enumerate(central_vertex)]\n",
    "            )\n",
    "        all_vertices.extend(\n",
    "            [\n",
    "                [central_vertex]+list(comb) for comb in \n",
    "                itertools.combinations(other_verts, 2)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # sort these by wall\n",
    "    all_vertices=torch.tensor(all_vertices)\n",
    "\n",
    "    wall_idxs = give_wall_idx(all_vertices)\n",
    "\n",
    "    return all_vertices, wall_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_ballroom(sphere_positions: torch.Tensor, sphere_radii: torch.Tensor, device: str ='cpu'):\n",
    "    \"\"\" \n",
    "    The environment will be a 1x1x1 cube with different shaded walls\n",
    "\twe will insert (nonintersecting) spheres within this\n",
    "\n",
    "    the idea will be that each triangle has a corresponding object\n",
    "    which is indexed \n",
    "\n",
    "    For the walls of the room, this is which side its on, from 0-5\n",
    "\n",
    "    For the balls, this is just the index of the ball\n",
    "    (starting at 6)\n",
    "    \"\"\"\n",
    "    wall_shades = torch.linspace(.1, .9, 6).to(torch.float64)\n",
    "    \n",
    "    # now construct all the objects \n",
    "    all_triangles = []\n",
    "    all_object_idxs = []\n",
    "    # first build the room\n",
    "    wall_triangles, wall_idxs = make_room()\n",
    "    all_triangles.append(wall_triangles)\n",
    "    all_object_idxs.append(wall_idxs)\n",
    "    # Now add in the spheres\n",
    "    \n",
    "    all_triangles, all_object_idxs = torch.concatenate(all_triangles), torch.concatenate(all_object_idxs)\n",
    "        \n",
    "    BallRoom = Environment(\n",
    "        sphere_positions=sphere_positions.clone(), \n",
    "        sphere_radii=sphere_radii.clone(),\n",
    "        triangles=all_triangles.clone(),\n",
    "        object_idxs=all_object_idxs.clone(),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    BallRoom.wall_shades=wall_shades\n",
    "\n",
    "    return BallRoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RayEnsemble:\n",
    "    \"\"\" \n",
    "    Make an ensemble of rays that bounce off of spheres, and \n",
    "    get absorbed by walls.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            env: Environment, \n",
    "            view_position: torch.Tensor, \n",
    "            rotation: torch.Tensor, \n",
    "            phi: float | tuple[float, float], \n",
    "            theta: float | tuple[float, float], \n",
    "            x_num: int, \n",
    "            y_num: int, \n",
    "            device: torch.device | str ='cpu',\n",
    "            dtype: torch.dtype = torch.float64,\n",
    "            distance_shading=True,\n",
    "    ):\n",
    "        self.env = env \n",
    "        self.env.to(device=device, dtype=dtype)\n",
    "        self.view_position=view_position.to(dtype=torch.float64, device=torch.device(device))\n",
    "        self.rotation=rotation.to(dtype=torch.float64, device=torch.device(device))\n",
    "        if isinstance(phi, float):\n",
    "            self.phi=(-phi, phi)\n",
    "        else:\n",
    "            assert len(phi)==2\n",
    "            self.phi = (phi[0], phi[1]) \n",
    "\n",
    "        if isinstance(theta, float):\n",
    "            self.theta=(-theta, theta)\n",
    "        else:\n",
    "            assert len(theta)==2\n",
    "            self.theta = (theta[0], theta[1])  \n",
    "        self.x_num=x_num \n",
    "        self.y_num=y_num\n",
    "        self.device = device\n",
    "        self.dtype=dtype\n",
    "        self.distance_shading=distance_shading\n",
    "\n",
    "        # now create the tensor of rays \n",
    "        vectors = []\n",
    "        for phi_val in np.linspace(self.phi[0], self.phi[1], x_num):\n",
    "            for theta_val in np.linspace(self.theta[0], self.theta[1], y_num):\n",
    "                vectors.append(\n",
    "                    [\n",
    "                        np.cos(phi_val)*np.cos(theta_val),\n",
    "                        np.sin(phi_val)*np.cos(theta_val),\n",
    "                        np.sin(theta_val)\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "        # now apply the rotation to the vectors\n",
    "        self.vectors = einops.einsum(\n",
    "            rotation,\n",
    "            torch.tensor(vectors).to(torch.float64),\n",
    "            'i j, ... j -> ... i'\n",
    "        )\n",
    "\n",
    "        # now we need to create a tensor of values\n",
    "        self.final_ray_values = torch.full(\n",
    "            size = (self.vectors.shape[0],), \n",
    "            fill_value=-1,\n",
    "            dtype=torch.float64, \n",
    "            device=torch.device(device)\n",
    "        )\n",
    "\n",
    "        # and keep track of rays\n",
    "        self.ray_positions = torch.zeros_like(self.vectors, dtype=torch.float64, device=torch.device(device))\n",
    "\n",
    "        # next we need to shift the environment triangles by the position\n",
    "        # (allowing us to start at 0)\n",
    "        self.env.triangles = self.env.triangles.clone() - self.view_position\n",
    "        self.env.sphere_positions = self.env.sphere_positions.clone() - self.view_position\n",
    "\n",
    "        # which rays are active? (not yet absorbed)\n",
    "        self.unabsorbed_ray_indices = torch.arange(self.vectors.shape[0])\n",
    "    \n",
    "    @classmethod\n",
    "    def batch_triangle_ray_trace_step(\n",
    "            cls, \n",
    "            positions: torch.Tensor, \n",
    "            rays: torch.Tensor, \n",
    "            triangles: torch.Tensor\n",
    "        ):\n",
    "        \"\"\" \n",
    "        Solve the simple linear problem of finding the intersection \n",
    "        between a triangle (defined by 3 points) and a ray\n",
    "\n",
    "        positions: tensor of shape (num_rays, 3)\n",
    "        rays: tensor of shape (num_rays, 3)\n",
    "        triangles: tensor of shape (num_triangles, 3, 3)\n",
    "            corresponds to (num_triangles, three vectors, three spatial dims)\n",
    "        \n",
    "        return the tensor of ray multipliers:\n",
    "\n",
    "            a tensor of shape (num_rays, num_triangles)\n",
    "            This contains a float multiplier for each ray, indicating the scale multiplier \n",
    "            before it intersects the corresponding triangle \n",
    "            \n",
    "            If it never does, the corresponding element is -1\n",
    "\n",
    "        We determine this by solving the following:\n",
    "\n",
    "        c*v = z1 + a*(z2-z1) + b*(z3-z1)\n",
    "\n",
    "        Where we insist that 0<= a, b\n",
    "        that a+b<=1\n",
    "        (the ray intersects the plane in the convex hull of z1, z2, and z3)\n",
    "\n",
    "        and that c>=0 \n",
    "        (the triangle is ahead of the ray)\n",
    "\n",
    "        Suppose each ray lives at (0,0,0)\n",
    "        This is then a problem of first solving the following:\n",
    "\n",
    "        gi := (z2-z1)_{i}\n",
    "        hi := (z3-z1)_{i}\n",
    "\n",
    "        [\n",
    "            [g0, h0, -v0],\n",
    "            [g1, h1, -v1],\n",
    "            [g2, h2, -v2]\n",
    "        ] @ [\n",
    "            [a],\n",
    "            [b],\n",
    "            [c]\n",
    "        ] = -z1\n",
    "        \n",
    "        Then checking that the solution obeys the constraints\n",
    "\n",
    "        return the boolean mask (num_rays, num_triangles)\n",
    "        And return the corresponding scalar which multiplies each \n",
    "\n",
    "        Note that introducing position only changes one aspect:\n",
    "        in the equation, we essentially want to subtract off pos from each triangle vertex\n",
    "        This has no effect on difference terms\n",
    "        leaving us with \n",
    "\n",
    "        c*v = z1-pos + a*(z2-z1) + b*(z3-z1)\n",
    "        \"\"\"\n",
    "        num_triangles, _, _ = triangles.shape \n",
    "        num_rays, _ = rays.shape\n",
    "        # first, construct the tensor of matrices\n",
    "\n",
    "        # shape = (num_rays, num_triangles, 3 vectors in a triangle, 3 dims)\n",
    "        matrix_tensor = -triangles[:, :1, :].unsqueeze(0).expand(num_rays, num_triangles, 3, 3)\n",
    "        matrix_tensor += triangles.unsqueeze(0).expand(num_rays, num_triangles, 3, 3)\n",
    "\n",
    "        # now add the rays in \n",
    "        matrix_tensor[..., 0, :] -= rays.view(num_rays, 1, 3)\n",
    "\n",
    "        solution_tensor = -triangles[:, 0, :].unsqueeze(0).expand(num_rays, num_triangles, 3)\n",
    "        solution_tensor += positions.unsqueeze(1)\n",
    "\n",
    "        # great, now we have our matrix\n",
    "        # the first step is to check for zero determinants\n",
    "        has_sol_mask = ~torch.isclose(torch.linalg.det(matrix_tensor), torch.tensor(0.0, dtype=torch.float64))\n",
    "\n",
    "        # now we'll flatten, and only solve for those which have nonzero determinant \n",
    "        # we flip this (ij -> ji) so we can multiply on the left \n",
    "        matrix_tensor = einops.rearrange(matrix_tensor, \"n m i j -> (n m) j i\")\n",
    "        has_sol_mask = einops.rearrange(has_sol_mask, \"n m -> (n m)\")\n",
    "        solution_tensor = einops.rearrange(solution_tensor, \"n m i -> (n m) i\")\n",
    "\n",
    "        # now for those with any solution, we can solve \n",
    "        solutions = torch.linalg.solve(\n",
    "            matrix_tensor[has_sol_mask], \n",
    "            solution_tensor[has_sol_mask]\n",
    "        )\n",
    "\n",
    "        # Now check that it satisfies our criteria \n",
    "        # 1) \n",
    "        # that 0 <= a, b, c\n",
    "        # that a + b <= 1\n",
    "        good_sol_mask = (\n",
    "            solutions.min(dim=-1).values>=0\n",
    "        )&(\n",
    "            solutions[:, 1:].sum(-1)<=1\n",
    "        )&(\n",
    "            solutions[:, 0]>10**-5\n",
    "        ) \n",
    "\n",
    "        # use this to get the indices which have good solutions\n",
    "        good_sol_indxs = torch.nonzero(has_sol_mask, as_tuple=False).squeeze()[good_sol_mask]\n",
    "        \n",
    "        # And then rebuild the boolean mask of shape (num_rays, num_triangles)\n",
    "        final_sols = torch.full(size=(num_rays*num_triangles,), fill_value=-1, dtype=torch.float64)\n",
    "\n",
    "        final_sols[good_sol_indxs] = solutions[good_sol_mask, 0]\n",
    "\n",
    "        return final_sols.reshape((num_rays, num_triangles))\n",
    "\n",
    "    @classmethod\n",
    "    def batch_sphere_ray_trace_step(\n",
    "        cls, \n",
    "        positions: torch.Tensor, \n",
    "        rays: torch.Tensor, \n",
    "        sphere_centers: torch.Tensor, \n",
    "        sphere_radii: torch.Tensor\n",
    "    ):\n",
    "        \"\"\" \n",
    "        Solve for the intersections with the sphere \n",
    "\n",
    "        Return a tensor of shape (num_rays, num_spheres)\n",
    "        \n",
    "        the values are either -1 (no intersection)\n",
    "        or the constant multiplier giving the distance to the sphere\n",
    "\n",
    "        Note we can solve for this easily\n",
    "\n",
    "        We want solutions of \n",
    "\n",
    "        (c*v - (sphere_center-ray_position))**2 == radius**2\n",
    "\n",
    "        Note we have shifted such that the current ray position is 0\n",
    "        \n",
    "        d := sphere_center-ray_position\n",
    "        v.v = 1\n",
    "\n",
    "        (c*v - d)**2 == r**2\n",
    "\n",
    "        c**2 - 2*c*(v.d) + (d.d - r**2) == 0\n",
    "\n",
    "        c = (2*(v.d) +/- torch.sqrt(4 * (v.d)**2 - 4 * (d.d - r**2)))/2\n",
    "\n",
    "        c = (v.d) +/- torch.sqrt((v.d)**2 - (d.d - r**2))\n",
    "\n",
    "        We require that c>0 (>10**-5)\n",
    "        \"\"\"\n",
    "        num_rays, _ = rays.shape \n",
    "        num_spheres, _ = sphere_centers.shape\n",
    "\n",
    "        # the constants we'll use to indicate how to multiply vectors to intersect spheres\n",
    "        # (num_rays, num_spheres)\n",
    "        constants = torch.full(size=(num_rays, num_spheres), fill_value=-1, dtype=torch.float64)\n",
    "        \n",
    "        # the position of the sphere centers wrt the ray positions\n",
    "        # (num_rays, num_spheres, 3)\n",
    "        delta = sphere_centers.unsqueeze(0)-positions.unsqueeze(1)\n",
    "        \n",
    "        # compute terms for the solution of c**2 - 2*c*(v.d) + (d.d - r**2) == 0\n",
    "        # v.delta, (num_rays, num_spheres)\n",
    "        v_dot_delta = (rays.unsqueeze(1)*delta).sum(-1)\n",
    "        # discriminant (num_rays, num_spheres)\n",
    "        discriminant = v_dot_delta**2 - ((delta**2).sum(-1) - sphere_radii.unsqueeze(0)**2)\n",
    "\n",
    "        # now the following is a subtle point:\n",
    "        # we want to treat these rays as internal or external\n",
    "        # But how do we treat them if they are currently touching a sphere?\n",
    "        # we will say that if it is touching the sphere, \n",
    "        # and v.d>0 (pointing within the sphere), then it is in the sphere.\n",
    "        # Otherwise, it is outside of the sphere.\n",
    "\n",
    "        distance_outside_radii = ((delta**2).sum(-1) - sphere_radii.unsqueeze(0)**2)\n",
    "\n",
    "        internal_reflecting = (torch.abs(distance_outside_radii)<10**-3) & (v_dot_delta>0)\n",
    "\n",
    "        internal_mask = (distance_outside_radii < 0) | internal_reflecting\n",
    "        external_mask = (~internal_mask) & (discriminant>=0) & (v_dot_delta>0)\n",
    "\n",
    "        # if we're outside, we expect two solutions, take v.d - sqrt ...\n",
    "        # if we're inside, we expect one solution, take v.d + sqrt...\n",
    "\n",
    "        constants[internal_mask] = (v_dot_delta + torch.sqrt(discriminant))[internal_mask]\n",
    "        constants[external_mask] = (v_dot_delta - torch.sqrt(discriminant))[external_mask]\n",
    "        \n",
    "        constants[constants<10**-5]=-1\n",
    "\n",
    "        return constants\n",
    "\n",
    "    def reflect_off_spheres(self, sphere_indices):\n",
    "        # this is applied only once the only vectors remaining are reflecting \n",
    "            \n",
    "        assert self.vectors.shape[0] == sphere_indices.shape[0]\n",
    "\n",
    "        normal_vectors = self.ray_positions-self.env.sphere_positions[sphere_indices]\n",
    "        normal_vectors /= normal_vectors.norm(2, -1, keepdim=True)\n",
    "\n",
    "        # now flip this component \n",
    "        self.vectors -= 2*normal_vectors*(self.vectors*normal_vectors).sum(-1, keepdim=True)\n",
    "\n",
    "    def resolve_rays(self, sphere_indices, triangle_indices, sphere_mask, triangle_mask):\n",
    "        \"\"\" \n",
    "        assign values \n",
    "\n",
    "        We'll multiply the current ray_value by the final shade\n",
    "        along with a distance scaler \n",
    "\n",
    "        Then add the value to final_ray_values\n",
    "\n",
    "        Finally, kill the elements from the vectors that have been absorbed\n",
    "        \"\"\"\n",
    "        object_indices=self.env.object_idxs[triangle_indices]\n",
    "        # get the shades \n",
    "        # note we start from 0,0,0\n",
    "        wall_distances = self.ray_positions[triangle_mask].norm(2, -1)\n",
    "        absorbing_objects = object_indices[triangle_mask]\n",
    "        if self.distance_shading:\n",
    "            shades = self.env.wall_shades[absorbing_objects]/(.1+ wall_distances/2)**(1.2)\n",
    "        else:\n",
    "            shades = self.env.wall_shades[absorbing_objects]\n",
    "        \n",
    "        # assign the final colors\n",
    "        self.final_ray_values[self.unabsorbed_ray_indices[triangle_mask]] = shades\n",
    "\n",
    "        # We only care about reflected rays\n",
    "        self.vectors = self.vectors[sphere_mask]\n",
    "        self.ray_positions = self.ray_positions[sphere_mask]\n",
    "        self.unabsorbed_ray_indices = self.unabsorbed_ray_indices[sphere_mask]\n",
    "\n",
    "        # reflect rays \n",
    "        self.reflect_off_spheres(\n",
    "            sphere_indices[sphere_mask], \n",
    "        )\n",
    "    \n",
    "    def propagate_rays(self):\n",
    "        \"\"\" \n",
    "        Now let's update vectors py propagating them to their closest intersecting object\n",
    "        Then updating their direction with a single reflection\n",
    "        \"\"\"\n",
    "        if not self.vectors.size:\n",
    "            return None \n",
    "        \n",
    "        triangle_intersection_consts = self.batch_triangle_ray_trace_step(\n",
    "            positions=self.ray_positions, \n",
    "            rays=self.vectors, \n",
    "            triangles=self.env.triangles\n",
    "        )\n",
    "\n",
    "        sphere_intersection_consts = self.batch_sphere_ray_trace_step(\n",
    "            positions=self.ray_positions, \n",
    "            rays=self.vectors, \n",
    "            sphere_centers=self.env.sphere_positions,\n",
    "            sphere_radii=self.env.sphere_radii\n",
    "        )\n",
    "\n",
    "        num_rays, num_triangles = triangle_intersection_consts.shape\n",
    "        num_rays, num_spheres = sphere_intersection_consts.shape\n",
    "\n",
    "        triangle_intersection_consts[triangle_intersection_consts<10**-5]=float('inf')\n",
    "        sphere_intersection_consts[sphere_intersection_consts<10**-5]=float('inf')\n",
    "\n",
    "        # now we have all the multipliers \n",
    "        # we're doing either 100% opaque or reflect\n",
    "        # for each ray find the closest intersection \n",
    "        triangle_hit_indices = triangle_intersection_consts.argmin(-1)\n",
    "        triangle_hit_consts = triangle_intersection_consts[torch.arange(num_rays), triangle_hit_indices]\n",
    "\n",
    "        sphere_hit_indices = sphere_intersection_consts.argmin(-1)\n",
    "        sphere_hit_consts = sphere_intersection_consts[torch.arange(num_rays), sphere_hit_indices]\n",
    "\n",
    "        hits_sphere = (triangle_hit_consts>=sphere_hit_consts) & torch.isfinite(sphere_hit_consts)\n",
    "        hits_triangle = (triangle_hit_consts<sphere_hit_consts) & torch.isfinite(triangle_hit_consts)\n",
    "\n",
    "        hit_consts = torch.minimum(sphere_hit_consts, triangle_hit_consts)\n",
    "\n",
    "        # update_all_positions\n",
    "        self.ray_positions = self.ray_positions + hit_consts.unsqueeze(-1) * self.vectors\n",
    "        \n",
    "        # three possible cases\n",
    "        # Case 1: the ray is absorbed\n",
    "        # Case 2: the ray is reflected\n",
    "        # Case 3: the ray goes off to infinity\n",
    "        self.resolve_rays(\n",
    "            sphere_hit_indices,\n",
    "            triangle_hit_indices,\n",
    "            hits_sphere,\n",
    "            hits_triangle\n",
    "        )\n",
    "    \n",
    "    def display(self, filename=None, invert=False):\n",
    "        fig, ax=plt.subplots(dpi=300)\n",
    "\n",
    "        shape = (self.x_num, self.y_num)\n",
    "\n",
    "        # format values\n",
    "        output_values = self.final_ray_values.clone()\n",
    "        output_values[output_values<0] = 0\n",
    "\n",
    "        if invert:\n",
    "            # we just want to show what hasnt been colored in yet \n",
    "            output_values[output_values>0] = 2.0\n",
    "\n",
    "        output_values = output_values.reshape(shape).T\n",
    "\n",
    "        ax.imshow(output_values, cmap='grey', vmin=0, vmax=2, origin='lower')\n",
    "\n",
    "        aspect = (self.theta[1]-self.theta[0]) / (self.phi[1]-self.phi[0])\n",
    "\n",
    "        aspect *= self.x_num/self.y_num\n",
    "\n",
    "        print(\"aspect=\",aspect)\n",
    "\n",
    "        ax.set_aspect(aspect)\n",
    "        ax.set_axis_off()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "            \n",
    "        return fig, ax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = construct_ballroom(\n",
    "    sphere_positions=torch.tensor([[2,2,2],]), \n",
    "    sphere_radii = torch.tensor([.3]), \n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "\n",
    "theta = -np.radians(45)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "\n",
    "rotation_matrix_y = torch.tensor([\n",
    "    [np.cos(theta), 0, -np.sin(theta)],\n",
    "    [0, 1, 0],\n",
    "    [np.sin(theta), 0, np.cos(theta)]\n",
    "]).to(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "re = RayEnsemble(\n",
    "    env=br,   \n",
    "    view_position = torch.tensor([0.1, .5, .9]), \n",
    "    rotation=rotation_matrix_y , #torch.eye(3, dtype=torch.float64), \n",
    "    phi=np.pi*.3, \n",
    "    theta=np.pi*.6/3, \n",
    "    x_num=1000, \n",
    "    y_num=1500, \n",
    "    distance_shading=False\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "    re.propagate_rays()\n",
    "\n",
    "re.display(f\"no_shading.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = construct_ballroom(\n",
    "    sphere_positions=torch.tensor([[2,2,2],]), \n",
    "    sphere_radii = torch.tensor([.3]), \n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "\n",
    "theta = -np.radians(45)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "theta = -np.radians(10)\n",
    "rotation_matrix_y = torch.tensor([\n",
    "    [np.cos(theta), 0, -np.sin(theta)],\n",
    "    [0, 1, 0],\n",
    "    [np.sin(theta), 0, np.cos(theta)]\n",
    "]).to(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "re = RayEnsemble(\n",
    "    env=br,   \n",
    "    view_position = torch.tensor([0.1, .99, .6]), \n",
    "    rotation=rotation_matrix_z@rotation_matrix_y , #torch.eye(3, dtype=torch.float64), \n",
    "    phi=np.pi*.3, \n",
    "    theta=np.pi*.6/3, \n",
    "    x_num=1000, \n",
    "    y_num=1500, \n",
    "    distance_shading=False\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "    re.propagate_rays()\n",
    "\n",
    "re.display(f\"cursed_room.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = construct_ballroom(\n",
    "    sphere_positions=torch.tensor([[2,2,2],]), \n",
    "    sphere_radii = torch.tensor([.3]), \n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "\n",
    "theta = -np.radians(30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "re = RayEnsemble(\n",
    "    env=br,   \n",
    "    view_position = torch.tensor([0.01, .5, .5]), \n",
    "    rotation=torch.eye(3, dtype=torch.float64), \n",
    "    phi=np.pi*.3, \n",
    "    theta=np.pi*.6/3, \n",
    "    x_num=1000, \n",
    "    y_num=1500, \n",
    "    distance_shading=True\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "    re.propagate_rays()\n",
    "\n",
    "re.display(f\"with_shading.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = construct_ballroom(\n",
    "    sphere_positions=torch.tensor([[.5,-.1,0.5], [1.2,.5,.5], [.5,1.2,0.5]]), \n",
    "    sphere_radii = torch.tensor([.3, .3, .3]), \n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "\n",
    "theta = -np.radians(30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "re = RayEnsemble(\n",
    "    env=br,   \n",
    "    view_position = torch.tensor([0.01, .9, .5]), \n",
    "    rotation=rotation_matrix_z,#torch.eye(3, dtype=torch.float32), \n",
    "    phi=np.pi*.3, \n",
    "    theta=np.pi*.6/3, \n",
    "    x_num=1000, \n",
    "    y_num=1500, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    re.display(f\"basic_images/reflection_{i}.png\") \n",
    "    re.propagate_rays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something cool with this \n",
    "\n",
    "What's cooler than fractals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inverse_coords(sphere_centers, sphere_radii):\n",
    "    num_spheres, _ = sphere_centers.shape\n",
    "    if len( sphere_radii.shape)==2:\n",
    "        sphere_radii = sphere_radii.squeeze(-1)\n",
    "    inverted_coords = torch.zeros((num_spheres, 5))\n",
    "\n",
    "    inverted_coords[..., :3] = sphere_centers / sphere_radii\n",
    "\n",
    "    r_squared = (sphere_centers**2).sum(-1) \n",
    "\n",
    "    inverted_coords[..., 3] = (r_squared - sphere_radii**2 - 1) / (2*sphere_radii)\n",
    "    inverted_coords[..., 4] = (r_squared - sphere_radii**2 + 1) / (2*sphere_radii)\n",
    "\n",
    "    return inverse_coords\n",
    "\n",
    "def give_curvature(inv_coords):\n",
    "    return inv_coords[..., 4] - inv_coords[..., 3]\n",
    "\n",
    "def standard_coords(inv_coords):\n",
    "    curvatures = give_curvature(inv_coords)\n",
    "    sphere_data = inv_coords[..., :3]/curvatures.unsqueeze(-1)\n",
    "\n",
    "    sphere_data[..., -1] = 1/curvatures\n",
    "\n",
    "    return sphere_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ApollonianPacking:\n",
    "    \"\"\" \n",
    "    This is actually fairly simple\n",
    "\n",
    "    each iteration has a bunch of sets of 5 spheres\n",
    "\n",
    "    Each of these 5-sphere-sets can generate another set of 5 sphere-sets\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.initial_basis = torch.eye(5, dtype=torch.int32)\n",
    "        self.rt2o2 = math.sqrt(2) / 2\n",
    "        self.rt6o2 = math.sqrt(6) / 2\n",
    "\n",
    "        self.iteration_idx = 0\n",
    "\n",
    "        # each generation contains the 5 spheres \n",
    "        # which define the next generation\n",
    "        self.inv_sphere_generations = [\n",
    "            torch.eye(5).to(dtype=torch.int32)\n",
    "        ]\n",
    "\n",
    "        self.bank = torch.eye(5).to(dtype=torch.int32)\n",
    "\n",
    "        self.conversion_matrix = torch.tensor(\n",
    "            [\n",
    "                [0, -1, 1, 1, -1],\n",
    "                [0, 1, -1, 1, -1],\n",
    "                [0, 1, 1, -1, -1],\n",
    "                [1, -1, -1, -1, -1],\n",
    "                [0, 1, 1, 1, 1]\n",
    "            ],\n",
    "            dtype=torch.float64\n",
    "        )\n",
    "\n",
    "        self.conversion_matrix[:3, :] *= self.rt2o2\n",
    "        self.conversion_matrix[4, :] *= self.rt6o2\n",
    "\n",
    "        self.iteration_tensor = (torch.eye(5)[:, None] +  torch.eye(5)[None, :] )\n",
    "        self.iteration_tensor[torch.arange(5), torch.arange(5), torch.arange(5)] -= 3\n",
    "        self.iteration_tensor = self.iteration_tensor.to(dtype=torch.int32)\n",
    "    \n",
    "    @property\n",
    "    def iterations(self) -> int:\n",
    "        return len(self.inv_sphere_generations)\n",
    "\n",
    "    def inverse_coords(self, sphere_centers, sphere_radii):\n",
    "        num_spheres, _ = sphere_centers.shape\n",
    "        if len( sphere_radii.shape)==2:\n",
    "            sphere_radii = sphere_radii.squeeze(-1)\n",
    "        inverted_coords = torch.zeros((num_spheres, 5))\n",
    "\n",
    "        inverted_coords[..., :3] = sphere_centers / sphere_radii\n",
    "\n",
    "        r_squared = (sphere_centers**2).sum(-1) \n",
    "\n",
    "        inverted_coords[..., 3] = (r_squared - sphere_radii**2 - 1) / (2*sphere_radii)\n",
    "        inverted_coords[..., 4] = (r_squared - sphere_radii**2 + 1) / (2*sphere_radii)\n",
    "\n",
    "        return inverted_coords\n",
    "\n",
    "    def give_curvature(self, inv_coords):\n",
    "        return inv_coords[..., 4] - inv_coords[..., 3]\n",
    "\n",
    "    def standard_coords(self, inv_coords):\n",
    "        curvatures = self.give_curvature(inv_coords)\n",
    "        sphere_data = inv_coords[..., :4]/curvatures.unsqueeze(-1)\n",
    "\n",
    "        sphere_data[..., -1] = 1/curvatures\n",
    "\n",
    "        return sphere_data\n",
    "\n",
    "    def SpecialToCartesian(self, inverted_spheres):\n",
    "        assert inverted_spheres.shape[-1]==5\n",
    "\n",
    "        transformed_inverse_coords = einops.einsum(\n",
    "            self.conversion_matrix, inverted_spheres.to(dtype=torch.float64), \"i j, ... j -> ... i\"\n",
    "        )\n",
    "\n",
    "        return self.standard_coords(transformed_inverse_coords)\n",
    "    \n",
    "    def obtain_new_generation(self) -> torch.Tensor:\n",
    "        \"\"\" \n",
    "        given the current spheres (in inverted coordinates)\n",
    "        return the next generation.\n",
    "        \"\"\"\n",
    "        # group for next generation\n",
    "        tmp = einops.repeat(\n",
    "            self.inv_sphere_generations[-1], \n",
    "            \"a c -> a b c\",\n",
    "            b=5\n",
    "        )\n",
    "        \n",
    "        # obtain next coordinates\n",
    "        next_coords = einops.einsum(\n",
    "            self.iteration_tensor.to(torch.int64),\n",
    "            tmp.to(torch.int64),\n",
    "            \"base_sphere d1 d2, group_size base_sphere d2 -> group_size base_sphere d1\"\n",
    "        )\n",
    "\n",
    "        # remove repeated coordinates\n",
    "        pruned_coords = torch.unique(einops.rearrange(\n",
    "            next_coords, \n",
    "            \"group_size base_sphere1 d1 -> (group_size base_sphere1) d1\"\n",
    "        ), dim=0)\n",
    "\n",
    "        # remove those in the bank \n",
    "        old_tensor_mask = (\n",
    "            pruned_coords[:, None, :] == self.bank[None, :, :]\n",
    "        ).all(-1).any(-1)\n",
    "\n",
    "        new_generation = pruned_coords[~old_tensor_mask]\n",
    "\n",
    "        self.bank = torch.concat(\n",
    "            [self.bank, new_generation]\n",
    "        )\n",
    "\n",
    "        self.inv_sphere_generations.append(\n",
    "            new_generation\n",
    "        )\n",
    "\n",
    "        return new_generation\n",
    "    \n",
    "    def output_all_spheres(self):\n",
    "        # check for repeats, then return the spheres in \n",
    "        # their real-space coords\n",
    "\n",
    "        # remove duplicates from each generation\n",
    "        real_space_bank = self.SpecialToCartesian(self.bank)\n",
    "        sphere_centers = real_space_bank[:, :3]\n",
    "        sphere_radii = real_space_bank[:, -1]\n",
    "        \n",
    "        good_mask = (sphere_radii>0) & torch.isfinite(sphere_radii)\n",
    "\n",
    "        sphere_centers = sphere_centers[good_mask]\n",
    "        sphere_radii = sphere_radii[good_mask]\n",
    "\n",
    "        return sphere_centers, sphere_radii\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.inv_sphere_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the number of spheres at each generation \n",
    "\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "\n",
    "ap  = ApollonianPacking()\n",
    "\n",
    "for i in range(7):\n",
    "    ap.obtain_new_generation()\n",
    "\n",
    "gen_sizes = [len(g) for g in ap.inv_sphere_generations]\n",
    "\n",
    "tot_sizes = [gen_sizes[0]]\n",
    "for i in range(1, len(gen_sizes)):\n",
    "    tot_sizes.append(tot_sizes[-1]+gen_sizes[i])\n",
    "\n",
    "ax.plot(range(1, 1+ len(tot_sizes)), tot_sizes)\n",
    "ax.scatter(range(1, 1+ len(tot_sizes)), tot_sizes)\n",
    "\n",
    "ax.set_title(\"Spheres in Apollonian Sphere Packing\", fontsize=18)\n",
    "ax.set_ylabel(\"Number of Spheres\", fontsize=16)\n",
    "ax.set_xlabel(\"Generation\", fontsize=16)\n",
    "\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_ap_spheres(gens, last_gen = False):\n",
    "    ap  = ApollonianPacking()\n",
    "\n",
    "    for i in range(gens):\n",
    "        ap.obtain_new_generation()\n",
    "    \n",
    "    if last_gen:\n",
    "        ap.bank = ap.inv_sphere_generations[-1]\n",
    "\n",
    "    final_spheres, final_radii = ap.output_all_spheres()\n",
    "    all_radii = torch.sqrt((final_spheres**2).sum(-1)) + final_radii + .2\n",
    "\n",
    "    final_spheres /= 2*all_radii.unsqueeze(-1)\n",
    "\n",
    "    final_radii /= 2*all_radii\n",
    "\n",
    "    final_spheres += torch.tensor([[0.5, 0.5, 0.5]])\n",
    "\n",
    "    return final_spheres, final_radii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want a banner image\n",
    "\n",
    "Ill make a high-res one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spheres, final_radii = give_ap_spheres(gens=gens, last_gen=True)\n",
    "\n",
    "br = construct_ballroom(\n",
    "    sphere_positions=final_spheres, \n",
    "    sphere_radii = final_radii, \n",
    "    device='cpu'\n",
    ")\n",
    "print(br.sphere_positions)\n",
    "print(br.sphere_radii)\n",
    "\n",
    "theta = np.radians(-30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_y = torch.tensor([\n",
    "    [np.cos(theta), 0, -np.sin(theta)],\n",
    "    [0,1,0],\n",
    "    [np.sin(theta), 0, np.cos(theta)]\n",
    "]).to(torch.float64)\n",
    "\n",
    "theta = np.radians(30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "\n",
    "tot_matrix = rotation_matrix_y@rotation_matrix_z\n",
    "\n",
    "xnum=3_000\n",
    "ynum=3_000\n",
    "\n",
    "total_output = np.zeros((xnum, ynum))\n",
    "\n",
    "slices = 100\n",
    "\n",
    "theta_intervals = []\n",
    "endpoints = np.linspace(-np.pi*.6/3, np.pi*.6/3, slices+1)\n",
    "for i in range(slices):\n",
    "    theta_intervals.append(\n",
    "        (endpoints[i], endpoints[i+1])\n",
    "    )\n",
    "\n",
    "for i in range(slices):\n",
    "    print(f\"starting slice {i}\")\n",
    "    final_spheres, final_radii = give_ap_spheres(gens=gens, last_gen=True)\n",
    "\n",
    "    br = construct_ballroom(\n",
    "        sphere_positions=final_spheres, \n",
    "        sphere_radii = final_radii, \n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "    re = RayEnsemble(\n",
    "        env=br,   \n",
    "        view_position = torch.tensor([0.01, .2, .8]), \n",
    "        rotation=tot_matrix, #torch.eye(3, dtype=torch.float64), \n",
    "        phi=np.pi*.3, \n",
    "        theta=theta_intervals[i], \n",
    "        x_num=xnum, \n",
    "        y_num=ynum//slices, \n",
    "    )\n",
    "\n",
    "    invert=False\n",
    "\n",
    "    for j in range(1000):\n",
    "        \n",
    "        re.propagate_rays()\n",
    "    \n",
    "    shape = (re.x_num, re.y_num)\n",
    "\n",
    "    # format values\n",
    "    output_values = re.final_ray_values.clone()\n",
    "    output_values[output_values<0] = 0\n",
    "\n",
    "    if invert:\n",
    "        # we just want to show what hasnt been colored in yet \n",
    "        output_values[output_values>0] = 2.0\n",
    "\n",
    "    output_values = output_values.reshape(shape)\n",
    "\n",
    "    print(\"output_values.shape\",output_values.shape)\n",
    "\n",
    "    print(i*(ynum//slices), (i+1)*(ynum//slices))\n",
    "\n",
    "    total_output[:, i*(ynum//slices):(i+1)*(ynum//slices)] = output_values\n",
    "\n",
    "    print(f\"finishing slice {i}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spheres.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=1_000)\n",
    "\n",
    "ax.imshow(total_output.T, cmap='grey', vmin=0, vmax=2, origin='lower')\n",
    "\n",
    "aspect = (2*endpoints[-1]) / (2*np.pi*.3)\n",
    "\n",
    "aspect *= xnum/ynum\n",
    "\n",
    "print(\"aspect=\",aspect)\n",
    "\n",
    "ax.set_aspect(aspect)\n",
    "ax.set_axis_off()\n",
    "\n",
    "\n",
    "print(\"aspect=\",aspect)\n",
    "\n",
    "ax.set_aspect(aspect)\n",
    "ax.set_axis_off()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"last_gen_6_Banner.png\", bbox_inches='tight', pad_inches=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_zoom_pic(z, re= None, target_phi_frac=None, target_theta_frac=None, zoom_at_target=None):\n",
    "    if re is None:\n",
    "\n",
    "        ap  = ApollonianPacking()\n",
    "\n",
    "        final_spheres, final_radii = ap.output_all_spheres()\n",
    "        all_radii = torch.sqrt((final_spheres**2).sum(-1)) + final_radii + .2\n",
    "\n",
    "        final_spheres /= 2*all_radii.unsqueeze(-1)\n",
    "\n",
    "        final_spheres += torch.tensor([[.5, .5, .5]])\n",
    "\n",
    "        final_radii /= 2*all_radii\n",
    "\n",
    "        br = construct_ballroom(\n",
    "            sphere_positions=final_spheres, \n",
    "            sphere_radii = final_radii, \n",
    "            device='cpu'\n",
    "        )\n",
    "        print(br.sphere_positions)\n",
    "        print(br.sphere_radii)\n",
    "\n",
    "        theta = np.radians(-30)  # Convert 30 degrees to radians\n",
    "        rotation_matrix_y = torch.tensor([\n",
    "            [np.cos(theta), 0, -np.sin(theta)],\n",
    "            [0,1,0],\n",
    "            [np.sin(theta), 0, np.cos(theta)]\n",
    "        ]).to(torch.float64)\n",
    "\n",
    "        theta = np.radians(30)  # Convert 30 degrees to radians\n",
    "        rotation_matrix_z = torch.tensor([\n",
    "            [np.cos(theta), -np.sin(theta), 0],\n",
    "            [np.sin(theta), np.cos(theta), 0],\n",
    "            [0, 0, 1]\n",
    "        ]).to(torch.float64)\n",
    "\n",
    "        tot_matrix = rotation_matrix_y@rotation_matrix_z\n",
    "\n",
    "        # current_center_theta -0.008892884642861063\n",
    "        # current_center_phi -0.03598221109224081\n",
    "\n",
    "        current_center_phi = np.float64(-0.03598221109224081)\n",
    "        current_center_theta = np.float64(-0.008892884642861063)\n",
    "\n",
    "        if target_phi_frac is None:\n",
    "            new_phi = (current_center_phi + np.float64(-0.9424777960769379)/z, current_center_phi + np.float64(0.9424777960769379)/z)\n",
    "        else:\n",
    "            \"\"\"\n",
    "            we want to be zooming into an interesting target point \n",
    "            ie we want the fraction of the phi where our interesting thing is to be .5\n",
    "            0 = current_center_phi + delta + (target_phi_frac*2*const./z - const./z)\n",
    "            and we have current_center_phi=0\n",
    "\n",
    "            But this isnt going to work perfectly\n",
    "            instead, we'll have to correct, and repeatedly update current_center_phi\n",
    "\n",
    "            when z was target zoom, we had to be at a certain fraction in the image\n",
    "            delta = (target_phi_frac*2*const./z - const./z)\n",
    "            \"\"\"\n",
    "            const = np.float64(-0.9424777960769379)\n",
    "\n",
    "            current_center_phi += (target_phi_frac*2 - 1)*const / zoom_at_target\n",
    "\n",
    "            new_phi = (current_center_phi + np.float64(-0.9424777960769379)/z, current_center_phi + np.float64(0.9424777960769379)/z)\n",
    "        \n",
    "        if target_theta_frac is None:\n",
    "            new_theta = (current_center_theta + np.float64(-0.6283185307179586)/z, current_center_theta + np.float64(0.6283185307179586)/z)\n",
    "        else: \n",
    "            const = np.float64(-0.6283185307179586)\n",
    "\n",
    "            current_center_theta += (target_theta_frac*2 - 1)*const / zoom_at_target\n",
    "\n",
    "            new_theta = (current_center_theta + np.float64(-0.6283185307179586)/z, current_center_theta + np.float64(0.6283185307179586)/z)\n",
    "\n",
    "\n",
    "        re = RayEnsemble(\n",
    "            env=br,   \n",
    "            view_position = torch.tensor([0.01, .2, .8]), \n",
    "            rotation=tot_matrix, #torch.eye(3, dtype=torch.float64), \n",
    "            phi=new_phi, \n",
    "            theta=new_theta, \n",
    "            x_num=1500, \n",
    "            y_num=1500, \n",
    "        )\n",
    "\n",
    "    \"\"\" \n",
    "    stop zooming when doing one more iteration \n",
    "    changes the fraction still reflecting by < threshold\n",
    "    \"\"\"\n",
    "    cur = (re.final_ray_values<0).sum()\n",
    "    count=0\n",
    "    while count<10 or cur / re.final_ray_values.size()[0] > .05:\n",
    "        #print(cur / re.final_ray_values.size()[0])\n",
    "        \n",
    "        re.propagate_rays()\n",
    "        cur = (re.final_ray_values<0).sum()\n",
    "        count+=1\n",
    "\n",
    "        if count >25:\n",
    "            break\n",
    "    \n",
    "    shape = (re.x_num, re.y_num)\n",
    "\n",
    "    # format values\n",
    "    output_values = re.final_ray_values.clone()\n",
    "    output_values[output_values<0] = 0\n",
    "\n",
    "    output_values = output_values.reshape(shape).T\n",
    "\n",
    "    np.save(f\"serpinski_zoom/serpinski_zoom_{z}_inverted_app.npy\", output_values)\n",
    "\n",
    "    re.display(f\"serpinski_zoom/serpinski_zoom_{z}_inverted_app.png\", invert=True) \n",
    "\n",
    "    print(\"current_center_theta\", current_center_theta)\n",
    "    print(\"current_center_phi\", current_center_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.inv_sphere_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert=False\n",
    "num_gens = len(ap.inv_sphere_generations)\n",
    "\n",
    "for i in range(18):\n",
    "    \n",
    "    re.propagate_rays()\n",
    "\n",
    "    if invert:\n",
    "        re.display(f\"fractal_folder/num_gens_{num_gens}_inverted_app_{i}.png\", invert=True) \n",
    "    else:\n",
    "        re.display(f\"fractal_folder/num_gens_{num_gens}_app_{i}.png\", invert=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = construct_ballroom(\n",
    "    sphere_positions=final_spheres, \n",
    "    sphere_radii = final_radii, \n",
    "    device='cpu'\n",
    ")\n",
    "print(br.sphere_positions)\n",
    "print(br.sphere_radii)\n",
    "\n",
    "theta = np.radians(-30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_y = torch.tensor([\n",
    "    [np.cos(theta), 0, -np.sin(theta)],\n",
    "    [0,1,0],\n",
    "    [np.sin(theta), 0, np.cos(theta)]\n",
    "]).to(torch.float64)\n",
    "\n",
    "theta = np.radians(30)  # Convert 30 degrees to radians\n",
    "rotation_matrix_z = torch.tensor([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "]).to(torch.float64)\n",
    "\n",
    "tot_matrix = rotation_matrix_y@rotation_matrix_z\n",
    "\n",
    "\n",
    "\n",
    "re = RayEnsemble(\n",
    "    env=br,   \n",
    "    view_position = torch.tensor([0.01, .2, .8]), \n",
    "    rotation=tot_matrix, #torch.eye(3, dtype=torch.float64), \n",
    "    phi=np.pi*.3, \n",
    "    theta=np.pi*.6/3, \n",
    "    x_num=1500, \n",
    "    y_num=1500, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert=True\n",
    "num_gens = len(ap.inv_sphere_generations)\n",
    "\n",
    "for i in range(18):\n",
    "    \n",
    "    re.propagate_rays()\n",
    "\n",
    "    if invert:\n",
    "        re.display(f\"fractal_folder/num_gens_{num_gens}_inverted_app_{i}.png\", invert=True) \n",
    "    else:\n",
    "        re.display(f\"fractal_folder/num_gens_{num_gens}_app_{i}.png\", invert=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom into the serpinski triangle and call it quits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_zoom_pic(z, re= None, target_phi_frac=None, target_theta_frac=None, zoom_at_target=None):\n",
    "    if re is None:\n",
    "\n",
    "        ap  = ApollonianPacking()\n",
    "\n",
    "        final_spheres, final_radii = ap.output_all_spheres()\n",
    "        all_radii = torch.sqrt((final_spheres**2).sum(-1)) + final_radii + .2\n",
    "\n",
    "        final_spheres /= 2*all_radii.unsqueeze(-1)\n",
    "\n",
    "        final_spheres += torch.tensor([[.5, .5, .5]])\n",
    "\n",
    "        final_radii /= 2*all_radii\n",
    "\n",
    "        br = construct_ballroom(\n",
    "            sphere_positions=final_spheres, \n",
    "            sphere_radii = final_radii, \n",
    "            device='cpu'\n",
    "        )\n",
    "        print(br.sphere_positions)\n",
    "        print(br.sphere_radii)\n",
    "\n",
    "        theta = np.radians(-30)  # Convert 30 degrees to radians\n",
    "        rotation_matrix_y = torch.tensor([\n",
    "            [np.cos(theta), 0, -np.sin(theta)],\n",
    "            [0,1,0],\n",
    "            [np.sin(theta), 0, np.cos(theta)]\n",
    "        ]).to(torch.float64)\n",
    "\n",
    "        theta = np.radians(30)  # Convert 30 degrees to radians\n",
    "        rotation_matrix_z = torch.tensor([\n",
    "            [np.cos(theta), -np.sin(theta), 0],\n",
    "            [np.sin(theta), np.cos(theta), 0],\n",
    "            [0, 0, 1]\n",
    "        ]).to(torch.float64)\n",
    "\n",
    "        tot_matrix = rotation_matrix_y@rotation_matrix_z\n",
    "\n",
    "        # current_center_theta -0.008892884642861063\n",
    "        # current_center_phi -0.03598221109224081\n",
    "\n",
    "        current_center_phi = np.float64(-0.03598221109224081)\n",
    "        current_center_theta = np.float64(-0.008892884642861063)\n",
    "\n",
    "        if target_phi_frac is None:\n",
    "            new_phi = (current_center_phi + np.float64(-0.9424777960769379)/z, current_center_phi + np.float64(0.9424777960769379)/z)\n",
    "        else:\n",
    "            \"\"\"\n",
    "            we want to be zooming into an interesting target point \n",
    "            ie we want the fraction of the phi where our interesting thing is to be .5\n",
    "            0 = current_center_phi + delta + (target_phi_frac*2*const./z - const./z)\n",
    "            and we have current_center_phi=0\n",
    "\n",
    "            But this isnt going to work perfectly\n",
    "            instead, we'll have to correct, and repeatedly update current_center_phi\n",
    "\n",
    "            when z was target zoom, we had to be at a certain fraction in the image\n",
    "            delta = (target_phi_frac*2*const./z - const./z)\n",
    "            \"\"\"\n",
    "            const = np.float64(-0.9424777960769379)\n",
    "\n",
    "            current_center_phi += (target_phi_frac*2 - 1)*const / zoom_at_target\n",
    "\n",
    "            new_phi = (current_center_phi + np.float64(-0.9424777960769379)/z, current_center_phi + np.float64(0.9424777960769379)/z)\n",
    "        \n",
    "        if target_theta_frac is None:\n",
    "            new_theta = (current_center_theta + np.float64(-0.6283185307179586)/z, current_center_theta + np.float64(0.6283185307179586)/z)\n",
    "        else: \n",
    "            const = np.float64(-0.6283185307179586)\n",
    "\n",
    "            current_center_theta += (target_theta_frac*2 - 1)*const / zoom_at_target\n",
    "\n",
    "            new_theta = (current_center_theta + np.float64(-0.6283185307179586)/z, current_center_theta + np.float64(0.6283185307179586)/z)\n",
    "\n",
    "\n",
    "        re = RayEnsemble(\n",
    "            env=br,   \n",
    "            view_position = torch.tensor([0.01, .2, .8]), \n",
    "            rotation=tot_matrix, #torch.eye(3, dtype=torch.float64), \n",
    "            phi=new_phi, \n",
    "            theta=new_theta, \n",
    "            x_num=1500, \n",
    "            y_num=1500, \n",
    "        )\n",
    "\n",
    "    \"\"\" \n",
    "    stop zooming when doing one more iteration \n",
    "    changes the fraction still reflecting by < threshold\n",
    "    \"\"\"\n",
    "    cur = (re.final_ray_values<0).sum()\n",
    "    count=0\n",
    "    while count<10 or cur / re.final_ray_values.size()[0] > .05:\n",
    "        #print(cur / re.final_ray_values.size()[0])\n",
    "        \n",
    "        re.propagate_rays()\n",
    "        cur = (re.final_ray_values<0).sum()\n",
    "        count+=1\n",
    "\n",
    "        if count >25:\n",
    "            break\n",
    "    \n",
    "    shape = (re.x_num, re.y_num)\n",
    "\n",
    "    # format values\n",
    "    output_values = re.final_ray_values.clone()\n",
    "    output_values[output_values<0] = 0\n",
    "\n",
    "    output_values = output_values.reshape(shape).T\n",
    "\n",
    "    np.save(f\"serpinski_zoom/serpinski_zoom_{z}_inverted_app.npy\", output_values)\n",
    "\n",
    "    re.display(f\"serpinski_zoom/serpinski_zoom_{z}_inverted_app.png\", invert=True) \n",
    "\n",
    "    print(\"current_center_theta\", current_center_theta)\n",
    "    print(\"current_center_phi\", current_center_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in (1.5 ** np.arange(60)):\n",
    "    give_zoom_pic(z, re= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zoomed_image(output_values, filename, frac):\n",
    "    aspect=2/3\n",
    "    \n",
    "    # Calculate the indices for cropping\n",
    "    ny, nx = output_values.shape\n",
    "    xmin = int((1 - frac) * nx / 2)\n",
    "    xmax = int((1 + frac) * nx / 2)\n",
    "    ymin = int((1 - frac) * ny / 2)\n",
    "    ymax = int((1 + frac) * ny / 2)\n",
    "\n",
    "    # Crop the array to zoom in\n",
    "    output_values = output_values[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Plot the zoomed-in image\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(output_values, cmap='grey', vmin=0, vmax=2, origin='lower')\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    # Remove axes and spines as before\n",
    "    ax.set_axis_off()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Save the figure at high resolution\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video_frames(z=1.5, frames_per_zoom=24, invert=False):\n",
    "\n",
    "    def current_zoom(file):\n",
    "        i1 = file.rindex(\"_inverted_app\")\n",
    "        i0 = (file[:i1].rindex(\"_\") + 1)\n",
    "        return float(file[i0:i1])\n",
    "\n",
    "    files = sorted(glob.glob(\"serpinski_zoom/*_inverted_app.npy\"), key = current_zoom)\n",
    "\n",
    "    for file in files:\n",
    "        current_tot_zoom = current_zoom(file)\n",
    "        print(\"current_zoom = \",current_tot_zoom)\n",
    "\n",
    "        zoom_fractions = 1 / (1.5**np.linspace(0, 1, frames_per_zoom+1)[:-1])\n",
    "\n",
    "        if invert:\n",
    "            file_names = [f\"zoom_video_files/inverted_zoom_video_files_{current_tot_zoom*cz}.png\" for cz in (1.5**np.linspace(0, 1, frames_per_zoom+1)[:-1])]\n",
    "        else:\n",
    "            file_names = [f\"zoom_video_files/zoom_video_files_{current_tot_zoom*cz}.png\" for cz in (1.5**np.linspace(0, 1, frames_per_zoom+1)[:-1])]\n",
    "\n",
    "        output_values = np.load(file)\n",
    "\n",
    "        if invert:\n",
    "            # we just want to show what hasnt been colored in yet \n",
    "            output_values[output_values>0] = 2.0\n",
    "\n",
    "        for file_name, frac in zip(file_names, zoom_fractions):\n",
    "            plot_zoomed_image(output_values, file_name, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def create_video_from_images(image_files, output_path, fps=24, bitrate='8000k', resolution=None):\n",
    "    \"\"\"\n",
    "    Create a high-quality video from a list of PNG images.\n",
    "\n",
    "    Args:\n",
    "        image_files (list of str): List of PNG image file paths.\n",
    "        output_path (str): Path where the output MP4 file will be saved.\n",
    "        fps (int, optional): Frames per second for the video. Defaults to 24.\n",
    "        bitrate (str, optional): Video bitrate (e.g., '5000k' for 5000 kbps). Adjust to balance quality and file size.\n",
    "        resolution (tuple, optional): Desired resolution as (width, height). If None, uses original image sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    def current_zoom(file):\n",
    "        i0 = file.rindex(\"_\")+1\n",
    "        i1 = -4\n",
    "        return float(file[i0:i1])\n",
    "\n",
    "    image_files = sorted(image_files, key = current_zoom)\n",
    "    \n",
    "\n",
    "    if not image_files:\n",
    "        raise ValueError(\"The list of image files is empty. Please provide valid image file paths.\")\n",
    "\n",
    "    # Create an image sequence clip\n",
    "    clip = ImageSequenceClip(image_files, fps=fps)\n",
    "\n",
    "    # Check if clip has valid duration\n",
    "    if clip.duration is None:\n",
    "        raise ValueError(\"The clip duration is None. Please check the images and fps value.\")\n",
    "\n",
    "    # Resize clip if resolution is specified\n",
    "    if resolution is not None:\n",
    "        clip = clip.resize(newsize=resolution)\n",
    "\n",
    "    # Write the video file with specified codec and bitrate\n",
    "    clip.write_videofile(\n",
    "        output_path,\n",
    "        codec='libx264',        # H.264 codec for MP4\n",
    "        bitrate=bitrate,        # Controls quality and file size\n",
    "        audio=False,            # No audio\n",
    "        threads=4,              # Speeds up the processing\n",
    "        preset='veryslow'         # Balance between encoding speed and compression\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_from_images(glob.glob('zoom_video_files/zoom_video_files*.png'), 'test_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video_frames(invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_from_images(glob.glob('zoom_video_files/inverted_zoom_video_files*.png'), 'test_video_inverted.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
